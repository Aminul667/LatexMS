\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts,amsmath,amssymb,suetterl}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[utf8]{inputenc}

\usepackage{fontawesome}
\DeclareUnicodeCharacter{2212}{-}
\usepackage{mathrsfs}

\usepackage[nodisplayskipstretch]{setspace}

\setstretch{1.5}
\setlength{\headheight}{15.2pt}

\pagestyle{fancy}
\fancyfoot[C]{\thepage}
\fancyfoot[L]{Course Organizer: R. J. HARRIS}
\fancyfoot[R]{rosemary.harris@qmul.ac.uk}

% \renewcommand{\footrulewidth}{0pt}
\renewcommand{\headrulewidth}{0pt}
\parindent 0ex
\setlength{\parskip}{1em}

\begin{document}
  \textbf{MTH734U/MTHM012} \hfill \textbf{Mathematical Sciences}\\
  \textbf{Semester B 2010 - 2011} \hfill \textbf{QMUL}
  \begin{center}
    \textbf{\huge Week 2}
  \end{center}
  \hrule \vspace{2mm} \hrule
  %
  \section*{Key Objective:}
  \textit{Know the definition of a \textbf{renewal process} and the associated random variables. Be able to derive the expression for the renewal function in terms of the distribution of interoccurrence times; perform explicit calculations for simple cases such as (i) the Poisson process and (ii) a gamma density of interccurrence times.}
  %
  \section*{Background:}
  Please read [T + K] Secs. VII.1 - VII.3. The formalism I introduced in the lecture can be found in Sec. VII.I so make sure you go over all the details and understand the relationships between the various random variables associated with a renewal process. Sec. VII.2 contains a number of applications and examples but, for the moment, you can skip the block replacement material in 2.2 since we will consider discrete renewal theory in much more detail later.\par
  It is usually hard to calculate the renewal function explicitly although, as we will see next week, one can make general statements about the asymptotic $t \to \infty$ behaviour. For continuous lifetimes there are two important cases where the renewal function can be relatively straightforwardly obtained: the Poisson process (see [T + K] Sec. V11.3) and a gamma density of interoccurence times. Both these cases feature in the problems overleaf.
  \newpage
  \section*{Problems:}
  \begin{enumerate}
    \item \textbf{Poisson process}\\
    Consider a renewal process in which the interoccurrence times have the exponential distribution with parameter $a > 0$, i.e.,
    $$
    f(x) = \alpha e^{-\alpha x},\quad \text{and $F(x) = 1 - e^{-\alpha x}$ for $x > 0$}.
    $$
    Find the renewal function $M(t) = E[N(t)]$ by each of the following methods.
    \begin{enumerate}
      \item Identify this as the Poisson process and use the known distribution of $N(t)$.
      \item Show directly by convolution that
      $$
      f_n(x) = \frac{\alpha^nx^{n - 1}e^{-\alpha x}}{(n - 1)!}\quad \text{for $x > 0$}.
      $$
      [Hint: Use induction.] Now write
      \begin{align*}
        M(t)
        &= \sum_{n = 1}^\infty F_n(t)\\
        &= \sum_{n = 1}^\infty\int_0^tf(x)dx
      \end{align*}
      and interchange the order of integral and sum to facilitate evaluation.
      \item Find the Laplace transform
      $$
      \hat{F}(\lambda):=\int_0^\infty f(x)e^{-\lambda x}dx
      $$
      and use this to obtain $\hat{F}_n(\lambda)$. Now you can sum over $n$ and then do the inverse Laplace transform to get an expression for $\sum_{n = 0}^\infty f_n(x)$ which leads to $M(t)$.
    \end{enumerate}
    \item \textbf{Mean excess life}\\
    Prove that the mean excess life can be evaluated in terms of the renewal function via the relation
    $$
    E[\gamma_t] = E[X_1]\{1 + M(t)\} - t.
    $$
    Verify this relationship explicitly for the Poisson process.
    \item \textbf{Gamma density}\\
    Now consider a renewal process in which the interoccurrence times have the gamma density:
    $$
    f(x) = xe^{-x}\quad\text{for $x \geq 0$}.
    $$
    Find the renewal function using either of the methods used in parts (b) or (c) of Question 1.
  \end{enumerate}
  %
  \newpage
  \textbf{MTH734U/MTHM012} \hfill \textbf{Mathematical Sciences}\\
  \textbf{Semester B 2010 - 2011} \hfill \textbf{QMUL}
  \begin{center}
    \textbf{\huge Solutions for Week 2}
  \end{center}
  \hrule \vspace{2mm} \hrule
  %
  \section*{General comments:}
  For background material to this problem sheet see secs. V11.1-V11.3 of [T+KI. In particular sec. V11.3 covers the interpretation of a Poission process as a renewal process with an exponential distribution of interoccurence times. Note that the book does not use Laplace transforms which in many cases provide an elegant alternative method of solution (see below).
  \section*{Solutions to Problems:}
  \begin{enumerate}
    \item \textbf{Solutions to Problems:}
    \begin{enumerate}
      \item The given distribution of interoccurence times defines a Poisson process with parameter $\alpha$. Hence the number of renewal events in time t has the Poisson distribution
      $$
      \text{Pr}\{N(t) = k\} = \frac{(\alpha t)^ke^{-\alpha t}}{k!},\quad k = 0, 1,\ldots
      $$
      and
      \begin{equation}\tag{2.1}
        \begin{aligned}[b]
          M(t)
          &= E[N(t)]\\
          &= \sum_{k = 1}^\infty k\text{Pr}\{N(t) = k\}\quad \text{[$k = 0$ term doesn't contribute]}\\
          &= \sum_{k = 1}^\infty \frac{(\alpha t)^ke^{-\aleph t}}{(k - 1)!}\\
          &= \alpha t\sum_{k = 1}^\infty \frac{(\alpha t)^{k-1}e^{-\alpha t}}{(k - 1)!}\\
          &= \alpha t\sum_{m = 0}^{\infty}\frac{(\alpha t)^me^{-\alpha t}}{m!}\quad \text{[Change variables $m = k - 1$]}\\
          &= \alpha t.
        \end{aligned}
      \end{equation}
      \item Proposition: The $n$-fold convolution of $f$ is given by
      \begin{equation}\tag{2.2}
        f_n(x) = \frac{\alpha^nx^{n - 1}e^{-\alpha x}}{(n - 1)!}\quad \text{for $x$ > 0},
      \end{equation}
      Proof: Use induction as follows.
      \begin{itemize}
        \item Base case is $n = 1$
        \begin{align*}
          f_1(x) 
          &= \alpha e^{-\alpha x}\quad \text{for $x > 0$}\\
          &= f(x).
        \end{align*}
        \item Assume Proposition is true for $n = k$. Then, for $x > 0$,
        \begin{align*}
          f_{k + 1}(x)
          &= \int_0^x f_k(x - y)f(y)dy\quad \text{[definition of convolution]}\\
          &= \int_0^\infty \frac{\alpha^k(x - y)^{k - 1}e^{-\alpha(x - y)}}{(k - 1)!}\alpha e^{-\alpha y}dy\quad \text{[by induction hypothesis]}\\
          &= \alpha^{k + 1}e^{-\alpha x}\int_0^\infty\frac{(x - y)^{k - 1}}{(k - 1)!}dy\\
          &= \alpha^{k + 1}e^{-\alpha x}\left[\frac{-(x - y)^k}{k!}\right]_{y = 0}^{y = x}\\
          &= \frac{\alpha^{k + 1}x^ke^{-\alpha x}}{k!}.
        \end{align*}
        So, if the proposition is true for $n = k$, it is also true for $n = k + 1$.
        \item Hence, by induction, the proposition is true for all integer $n \geq 1$.
      \end{itemize}
      Then, as instructed, use
      \begin{equation}\tag{2.3}
        \begin{aligned}[b]
          M(t)
          &= \sum_{n = 1}^\infty F_n(t)\\
          &= \sum_{n = 1}^\infty\int_0^t f_n(x)dx\\
          &= \int_0^t\left(\sum_{n = 1}^\infty f_n(x)\right)dx\\
          &= \int_0^t\left(\sum_{n = 1}^\infty \frac{\alpha^nx^{n - 1}e^{-\alpha x}}{(n - 1)!}\right)dx\\
          &= \int_0^t\left(\alpha\sum_{n = 1}^\infty\frac{(\alpha x)^{n - 1}e^{-\alpha x}}{(n - 1)!}\right)dx\\
          &= \int_0^t\alpha dx\\
          &= \alpha t.
        \end{aligned}
      \end{equation}
      \item Laplace transform:
      \begin{align*}
        \hat{F}(\lambda)
        &= \int_0^\infty f(x)e^{-\lambda x}dx\\
        &= \int_0^\infty \alpha e^{-\alpha x}e^{-\lambda x}dx\\
        &= \int_0^\infty \alpha e^{-(\alpha + \lambda)x}dx\\
        &= \left[\frac{-\alpha}{\alpha + \lambda}e^{-(\alpha + \lambda)x}\right]_{x = 0}^{x = \infty}\\
        &= \frac{\alpha}{\alpha + \lambda}
      \end{align*}
      [Strictly speaking, the integral only converges for $\alpha + \lambda > 0$ but it's not really necessary to write that here since $\lambda \geq 0$ is usually assumed for Laplace transforms and $\alpha > 0$ is given in the question.] Now, since the Laplace transform of a convolution is the product of the transforms, we have
      \begin{equation}\tag{2.4}
        \begin{aligned}[b]
          \hat{F}_n(\lambda) 
          &= (\hat{F}(\lambda))^n\\
          &= \left(\frac{\alpha}{(\alpha + \lambda)}\right)
        \end{aligned}
      \end{equation}
      and hence
      \begin{align*}
        \sum_{n = 1}^\infty\hat{F}_n(\lambda)
        &= \sum_{n = 1}^\infty \left(\frac{\alpha}{\alpha + \lambda}\right)^n\\
        &= \frac{\alpha}{\alpha + \lambda}\sum_{n = 0}^\infty\left(\frac{\alpha}{\alpha + \lambda}\right)^n\\
        &= \frac{\alpha}{\alpha + \lambda}\times \frac{1}{1 - \left(\frac{\alpha}{\alpha + \lambda}\right)}\\
        &= \frac{\alpha}{\lambda}.
      \end{align*}
      To do the inverse Laplace transform note that (cf. solutions to the Week 1 problem set)
      \begin{equation}\tag{2.5}
        \frac{\alpha}{\lambda} = \int_0^\infty e^{-\lambda x}\alpha dx
      \end{equation}
      The Laplace transform uniquely determines the distribution so
      $$
      \sum_{n = 1}^\infty f_n(x) = \alpha
      $$
      and
      \begin{equation}\tag{2.6}
        \begin{aligned}[b]
          M(t)
          &= \int_0^\infty\left(\sum_{n = 1}^\infty f_n(x)\right)dx\\
          &= \int_0^\infty \alpha dx\\
          &= \alpha t.
        \end{aligned}
      \end{equation}
      Note the happy agreement between results (2.1), (2.3) and (2.6).
    \end{enumerate}
  \end{enumerate}
\end{document}